{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.0f' % x)\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Data From NHTSA GES Repository Years 2010-2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differing data files and formats across years, as well as storage directories made it difficult to obtain data using a batch iteration directly from the file transfer protocol set up by NHTSA. Directories for specific years were downloaded manually. Due to complex variation of feature column names, value categories and filenames, the attribute names, years and filepaths were first stored in data containers for ease in building a data cleaning script.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories storing all sas files needed for each year in NHTSA GES dataset\n",
    "dir_years = [r\"C:\\Users\\murra667\\Documents\\Springboard\\Capstone_2\\After 2010\\GES10_PCSAS\\repost GES\", \n",
    "             r\"C:\\Users\\murra667\\Documents\\Springboard\\Capstone_2\\After 2010\\GES11_PCSAS\", \n",
    "             r\"C:\\Users\\murra667\\Documents\\Springboard\\Capstone_2\\After 2010\\GES12_PCSAS\", \n",
    "             r\"C:\\Users\\murra667\\Documents\\Springboard\\Capstone_2\\After 2010\\GES13_PCSAS\", \n",
    "             r\"C:\\Users\\murra667\\Documents\\Springboard\\Capstone_2\\After 2010\\GES2014SAS\", \n",
    "             r\"C:\\Users\\murra667\\Documents\\Springboard\\Capstone_2\\After 2010\\GES2015sas\"]\n",
    "# store dictionary of attributes to extract from each sas file type: person, accident, vehicle, vevent\n",
    "sas_file_dict = {\n",
    "              \"person\": \n",
    "              {\"cols\" :['VEHNO', 'VEH_NO', 'CASENUM', 'PER_TYP', 'AGE', 'SEX', 'ALC_RES', 'ALTRSULT']}, \n",
    "             \"accident\": \n",
    "              {\"cols\": ['CASENUM', 'MONTH', 'DAY_WEEK', 'YEAR', 'HOUR', 'MINUTE', 'LAND_USE',\n",
    "                        'RELJCT2', 'REL_ROAD', 'WRK_ZONE',\n",
    "              'INT_HWY', 'TYP_INT', 'NON_INVL', 'MAN_COL',\n",
    "              'MAX_SEV', 'MAN_COLL', 'PERNOTMVIT']}, \n",
    "             \"vehicle\" :\n",
    "              {\"cols\" : ['VEHNO', 'VEH_NO', 'CASENUM', 'TRAV_SP', 'VSPD_LIM', 'ACC_TYPE', 'MAKE', 'VNUM_LAN', 'NUMOCCS']},\n",
    "             \"vevent\": {\"cols\" : ['CASENUM', 'AOI1', 'GAD', 'VEHNO', 'VEH_NO']}\n",
    "                }\n",
    "\n",
    "# range of years stored in list \n",
    "years = list(range(2010,2016))\n",
    "# store data first by file type (person, accident, vehicle, vevent) then by year \n",
    "for file in sas_file_dict.keys():\n",
    "    sas_file_dict[file]['years'] = (dict(zip(years, dir_years)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First create a dataframe with Distracted Driving Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murra667\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# store dataframes of sas files containing distracted driving data\n",
    "distracted_dfs = []\n",
    "# iterate through years and their respective file directories\n",
    "for year, file in zip(years, dir_years):\n",
    "    global df\n",
    "    df = pd.read_sas(os.path.join(file, \"distract.sas7bdat\"))\n",
    "    if year == 2010:\n",
    "        df = df.rename(columns = {\"VEHNO\": \"VEH_NO\"})\n",
    "    df[\"VEH_NO\"] = df[\"VEH_NO\"].astype(str)\n",
    "    df[\"CASENUM\"] = df[\"CASENUM\"].astype(str)\n",
    "    # create unique identifier that creates a row for each car involved in\n",
    "    # any crash\n",
    "    df[\"CASENUM_VEH_NO\"] = df[\"CASENUM\"] + df[\"VEH_NO\"]\n",
    "    df = df.drop_duplicates(subset = \"CASENUM_VEH_NO\", keep = \"first\")\n",
    "    distracted_dfs.append(df)\n",
    "# concatenate the dataframes across years\n",
    "global distracted_df\n",
    "distracted_df = pd.concat(distracted_dfs)\n",
    "distracted_dfs.clear()\n",
    "distracted_df = distracted_df.drop_duplicates(keep = \"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring together NHTSA GES crash data across years and file types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murra667\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:79: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# update current_df during iteration\n",
    "global current_df\n",
    "# update dataframe of non-occupants involved in accidents and their case number\n",
    "involved_non_occupants  = []\n",
    "# concat years of each file type (person, accident, event, )\n",
    "concat_file_type = []\n",
    "# iterate through filetype and respective columns in sas_file_dict\n",
    "for file_type, file_type_attrs in sas_file_dict.items():\n",
    "    # iterate through each year \n",
    "    for year, file_list in (file_type_attrs['years'].items()):\n",
    "        filepath = os.path.join(file_list, (file_type + \".sas7bdat\"))\n",
    "        # access columns specific to year and file type\n",
    "        columns = file_type_attrs['cols']\n",
    "        # set mutable variable to adjust columns as necessary for year and file type\n",
    "        global columns_adj\n",
    "        # make a copy of columns \n",
    "        columns_adj = (columns.copy())\n",
    "        # adjust columns as necessary for year and file type\n",
    "        if year == 2010 and file_type != \"accident\": \n",
    "            columns_adj.remove(\"VEH_NO\")\n",
    "        if year ==  2010 and file_type == \"accident\":\n",
    "            columns_adj.remove('MAN_COLL')\n",
    "            columns_adj.remove('PERNOTMVIT')\n",
    "        if year ==  2010 and file_type == \"vevent\":\n",
    "            columns_adj.remove(\"AOI1\")\n",
    "        if year ==  2010 and file_type == \"person\":\n",
    "            columns_adj.remove('ALC_RES')\n",
    "        #if year ==  2010 and file_type == \"vehicle\":\n",
    "            #columns_adj.remove(\"MOD_YEAR\")\n",
    "        if year !=  2010 and file_type == \"accident\":\n",
    "            columns_adj.remove('MAN_COL')\n",
    "            columns_adj.remove('NON_INVL')\n",
    "        if year !=  2010 and file_type != \"accident\":\n",
    "            columns_adj.remove(\"VEHNO\")\n",
    "        if year !=  2010 and file_type == \"person\":\n",
    "            columns_adj.remove('ALTRSULT')\n",
    "        #if year !=  2010 and file_type == \"vehicle\":\n",
    "           # columns_adj.remove(\"MODEL_YR\")\n",
    "        if year !=  2010 and file_type == \"vevent\":\n",
    "            columns_adj.remove(\"GAD\")\n",
    "        \n",
    "        # read in current df and set columns appropriately \n",
    "        current_df = pd.read_sas(filepath)\n",
    "        # extract only person values where person is driver, i.e \"1\"\n",
    "        #if file_type == \"person\":\n",
    "        if file_type == \"person\":\n",
    "            current_df['non_motorist'] = 0\n",
    "            current_df.loc[(current_df['PER_TYP'] == 5) | (current_df['PER_TYP'] == 6) | (current_df['PER_TYP'] == 7) | (current_df['PER_TYP'] == 19), 'non_motorist'] = 1\n",
    "            non_occupants = current_df[['CASENUM', 'non_motorist']]\n",
    "            # capture data on involved non occupants (peds, cyclists, etc.)\n",
    "            # who would not be labeled as drivers in PER_TYP, as value 1\n",
    "            # which will be dropped in the lines below\n",
    "            involved_non_occupants.append(non_occupants)\n",
    "            del non_occupants\n",
    "            current_df = current_df.loc[current_df['PER_TYP'] == 1]\n",
    "        current_df = current_df[columns_adj]        \n",
    "        # rename column names appropriately for year and file type for joining\n",
    "        if year ==  2010 and file_type != \"accident\":\n",
    "            current_df = current_df.rename(columns = {\"VEHNO\" : \"VEH_NO\"})\n",
    "        if year ==  2010 and file_type == \"accident\": \n",
    "            current_df = current_df.rename(columns = {\"MAN_COL\" : \"MAN_COLL\", \"NON_INVL\" : \"PERNOTMVIT\"})\n",
    "        if file_type == \"person\":\n",
    "            current_df = current_df.rename(columns = {\"ALC_RES\" : \"ALTRSULT\"})\n",
    "        #if year ==  2010 and file_type == \"vehicle\":\n",
    "            #current_df = current_df.rename(columns = {\"MODEL_YR\" : \"MOD_YEAR\"})\n",
    "        if year ==  2010 and file_type == \"vevent\":\n",
    "            current_df = current_df.rename(columns = {\"GAD\" : \"AOI1\"})\n",
    "        current_df[\"CASENUM\"] = current_df[\"CASENUM\"].astype(str)\n",
    "        if file_type != \"accident\":\n",
    "            current_df = current_df.dropna(subset = [\"CASENUM\", \"VEH_NO\"]) \n",
    "            current_df[\"VEH_NO\"] = current_df[\"VEH_NO\"].astype(str)\n",
    "            current_df[\"CASENUM_VEH_NO\"] = current_df[\"CASENUM\"] + current_df[\"VEH_NO\"]\n",
    "        else:\n",
    "            current_df = current_df.dropna(subset = [\"CASENUM\"])\n",
    "        #  for each file type, across years, add to container for concatenation\n",
    "        concat_file_type.append(current_df)\n",
    "        \n",
    "    # concatenate file type across each year\n",
    "    current_df = pd.concat(concat_file_type)\n",
    "    # delete data conatiner after concatenation\n",
    "    concat_file_type.clear()\n",
    "    # use a special way to join the accident file, which has no \n",
    "    # vehicle number, and therefore no attribute CASENUM_VEH_NO which was\n",
    "    # created for all other file types \n",
    "    if file_type == \"accident\":\n",
    "        distracted_df = distracted_df.drop(columns = [\"CASENUM_y\"])\n",
    "        distracted_df = pd.merge(left=distracted_df, right=current_df, left_on='CASENUM_x', right_on='CASENUM')\n",
    "    # merge each file type into single dataframe (already concatenated by year)\n",
    "    else:\n",
    "        distracted_df = pd.merge(left = distracted_df, right = current_df, left_on=\"CASENUM_VEH_NO\", right_on=\"CASENUM_VEH_NO\")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure That Data is Kept On Accidents Where A Non-Motorist Is Involved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate involved non occupant data\n",
    "involved_non_occupant = pd.concat(involved_non_occupants)\n",
    "del (involved_non_occupants)\n",
    "# drop duplicates along the CASENUM_VEH_NO column\n",
    "involved_non_occupant = involved_non_occupant.drop_duplicates(subset = \"CASENUM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Main Dataframe with Dataframe Containing Crashes Involving Non-Motorists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murra667\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\murra667\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# drop duplicates along the CASENUM_VEH_NO column\n",
    "distracted_df = distracted_df.drop_duplicates(subset = \"CASENUM_VEH_NO\")\n",
    "#del distracted_df\n",
    "# drop columns\n",
    "final_df = distracted_df.drop(columns = [\"CASENUM_x\", \"CASENUM_y\", \"VEH_NO_x\", \"VEH_NO_y\", \"PSUSTRAT\", \"PSU\", \"STRATUM\", \"PERNOTMVIT\", \"PJ\"])\n",
    "involved_non_occupant[\"CASENUM\"] = involved_non_occupant['CASENUM'].astype(float)\n",
    "final_df[\"CASENUM\"] = final_df[\"CASENUM\"].astype(float)\n",
    "involved_non_occupant[\"CASENUM\"] = involved_non_occupant['CASENUM'].astype(str)\n",
    "final_df[\"CASENUM\"] = final_df[\"CASENUM\"].astype(str)\n",
    "final_df = involved_non_occupant.merge(final_df, how = \"right\", left_on = \"CASENUM\", right_on = \"CASENUM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"nhtsa_ges_extracted.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
